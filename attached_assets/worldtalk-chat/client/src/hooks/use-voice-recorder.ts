import { useState, useRef, useCallback } from 'react';

export interface VoiceRecorderState {
  isRecording: boolean;
  duration: number; // ç§’
  audioBlob: Blob | null;
  audioUrl: string | null;
  error: string | null;
  audioLevel: number; // 0-1 çœŸå®éŸ³é‡çº§åˆ«
  hasPermission: boolean; // æ˜¯å¦å·²è·å–éº¦å…‹é£æƒé™
}

export function useVoiceRecorder() {
  const [state, setState] = useState<VoiceRecorderState>({
    isRecording: false,
    duration: 0,
    audioBlob: null,
    audioUrl: null,
    error: null,
    audioLevel: 0,
    hasPermission: false
  });

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const startTimeRef = useRef<number>(0);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const streamRef = useRef<MediaStream | null>(null); // ç¼“å­˜çš„MediaStream
  
  // Web Audio API - ç”¨äºçœŸå®æ³¢å½¢
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);

  // é¢„å…ˆè¯·æ±‚éº¦å…‹é£æƒé™å¹¶ç¼“å­˜stream
  const ensurePermission = useCallback(async (): Promise<boolean> => {
    try {
      // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½');
      }

      // å¦‚æœå·²ç»æœ‰ç¼“å­˜çš„streamï¼Œç›´æ¥è¿”å›
      if (streamRef.current && streamRef.current.active) {
        setState(prev => ({ ...prev, hasPermission: true }));
        return true;
      }

      // è¯·æ±‚éº¦å…‹é£æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      setState(prev => ({ ...prev, hasPermission: true }));
      return true;
    } catch (error: any) {
      console.error('[useVoiceRecorder] éº¦å…‹é£æƒé™è¯·æ±‚å¤±è´¥:', error);
      let errorMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£';
      
      if (error.name === 'NotAllowedError') {
        errorMessage = 'è¯·å…è®¸ä½¿ç”¨éº¦å…‹é£æƒé™';
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'æœªæ£€æµ‹åˆ°éº¦å…‹é£è®¾å¤‡';
      } else if (error.name === 'NotSupportedError') {
        errorMessage = 'æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³';
      } else if (error.message) {
        errorMessage = error.message;
      }
      
      setState(prev => ({
        ...prev,
        hasPermission: false,
        error: errorMessage
      }));
      
      alert(errorMessage);
      return false;
    }
  }, []);

  const startRecording = useCallback(async () => {
    console.log('ğŸ¤ [useVoiceRecorder] startRecording è¢«è°ƒç”¨');
    try {
      // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        console.error('ğŸ¤ [useVoiceRecorder] æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³');
        throw new Error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½');
      }
      console.log('ğŸ¤ [useVoiceRecorder] æµè§ˆå™¨æ”¯æŒæ£€æŸ¥é€šè¿‡');

      // ä½¿ç”¨ç¼“å­˜çš„streamï¼Œå¦‚æœæ²¡æœ‰åˆ™è¯·æ±‚æ–°çš„
      let stream = streamRef.current;
      if (!stream || !stream.active) {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        streamRef.current = stream;
        setState(prev => ({ ...prev, hasPermission: true }));
      }
      
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 256;
      source.connect(analyser);
      
      audioContextRef.current = audioContext;
      analyserRef.current = analyser;
      
      const dataArray = new Float32Array(analyser.frequencyBinCount);
      const updateAudioLevel = () => {
        if (!analyserRef.current) return;
        
        analyser.getFloatTimeDomainData(dataArray);
        
        // è®¡ç®—RMSéŸ³é‡ï¼ˆ0-1ï¼‰
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          sum += dataArray[i] * dataArray[i];
        }
        const rms = Math.sqrt(sum / dataArray.length);
        const normalizedLevel = Math.min(1, rms * 3); // æ”¾å¤§3å€æé«˜çµæ•åº¦
        
        setState(prev => ({
          ...prev,
          audioLevel: normalizedLevel
        }));
        
        animationFrameRef.current = requestAnimationFrame(updateAudioLevel);
      };
      updateAudioLevel();
      
      // å°è¯•å¤šç§éŸ³é¢‘æ ¼å¼ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªæ”¯æŒçš„
      let mimeType = 'audio/webm;codecs=opus';
      const supportedTypes = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/mp4',
        'audio/ogg;codecs=opus',
        'audio/wav'
      ];

      const supportedType = supportedTypes.find(type => MediaRecorder.isTypeSupported(type));
      if (supportedType) {
        mimeType = supportedType;
      }

      console.log('ä½¿ç”¨éŸ³é¢‘æ ¼å¼:', mimeType);

      // åˆ›å»ºMediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType
      });
      
      audioChunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };
      
      mediaRecorder.onstop = () => {
        // ä½¿ç”¨å®é™…å½•åˆ¶çš„mimeType
        const actualMimeType = mediaRecorder.mimeType || 'audio/webm';
        const audioBlob = new Blob(audioChunksRef.current, { type: actualMimeType });
        const audioUrl = URL.createObjectURL(audioBlob);
        
        console.log('å½•éŸ³å®Œæˆ:', {
          size: audioBlob.size,
          type: audioBlob.type,
          duration: Math.floor((Date.now() - startTimeRef.current) / 1000)
        });
        
        setState(prev => ({
          ...prev,
          isRecording: false,
          audioBlob,
          audioUrl
        }));
        
        // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
        stream.getTracks().forEach(track => track.stop());
        
        // æ¸…é™¤Web Audio API
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current);
          animationFrameRef.current = null;
        }
        if (audioContextRef.current) {
          audioContextRef.current.close();
          audioContextRef.current = null;
        }
        analyserRef.current = null;
        
        // æ¸…é™¤è®¡æ—¶å™¨
        if (timerRef.current) {
          clearInterval(timerRef.current);
          timerRef.current = null;
        }
      };
      
      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start();
      startTimeRef.current = Date.now();
      
      // å¼€å§‹è®¡æ—¶ï¼ˆå¸¦è‡ªåŠ¨åœæ­¢é™åˆ¶ï¼‰
      const MAX_DURATION = 15; // æœ€å¤§å½•éŸ³æ—¶é•¿15ç§’
      timerRef.current = setInterval(() => {
        const elapsed = Math.floor((Date.now() - startTimeRef.current) / 1000);
        setState(prev => ({
          ...prev,
          duration: elapsed
        }));
        
        // è¶…è¿‡15ç§’è‡ªåŠ¨åœæ­¢
        if (elapsed >= MAX_DURATION) {
          console.log(`â±ï¸ å½•éŸ³å·²è¾¾${MAX_DURATION}ç§’ä¸Šé™ï¼Œè‡ªåŠ¨åœæ­¢`);
          if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
            mediaRecorderRef.current.stop();
          }
        }
      }, 100);
      
      setState({
        isRecording: true,
        duration: 0,
        audioBlob: null,
        audioUrl: null,
        error: null,
        audioLevel: 0,
        hasPermission: true
      });
      
    } catch (error: any) {
      console.error('å½•éŸ³å¯åŠ¨å¤±è´¥:', error);
      let errorMessage = 'æ— æ³•è®¿é—®éº¦å…‹é£';
      
      if (error.name === 'NotAllowedError') {
        errorMessage = 'è¯·å…è®¸ä½¿ç”¨éº¦å…‹é£æƒé™';
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'æœªæ£€æµ‹åˆ°éº¦å…‹é£è®¾å¤‡';
      } else if (error.name === 'NotSupportedError') {
        errorMessage = 'æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³';
      } else if (error.message) {
        errorMessage = error.message;
      }
      
      setState(prev => ({
        ...prev,
        isRecording: false,
        hasPermission: false,
        error: errorMessage
      }));
      
      // æ˜¾ç¤ºé”™è¯¯æç¤º
      alert(errorMessage);
    }
  }, []);

  const stopRecording = useCallback((): Promise<Blob | null> => {
    return new Promise((resolve) => {
      if (!mediaRecorderRef.current || !state.isRecording) {
        resolve(null);
        return;
      }

      const recorder = mediaRecorderRef.current;
      
      // ä¿å­˜å½“å‰çš„onstopå›è°ƒ
      const originalOnStop = recorder.onstop;
      
      // ä¸´æ—¶è¦†ç›–onstopå›è°ƒ
      recorder.onstop = (event) => {
        // å…ˆè°ƒç”¨åŸå§‹å›è°ƒ
        if (originalOnStop && recorder) {
          originalOnStop.call(recorder, event);
        }
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©stateæ›´æ–°
        setTimeout(() => {
          const audioBlob = new Blob(audioChunksRef.current, { 
            type: recorder?.mimeType || 'audio/webm' 
          });
          resolve(audioBlob);
        }, 100);
      };

      recorder.stop();
    });
  }, [state.isRecording]);

  const cancelRecording = useCallback(() => {
    if (mediaRecorderRef.current && state.isRecording) {
      mediaRecorderRef.current.stop();
      
      // æ¸…é™¤å½•éŸ³æ•°æ®
      audioChunksRef.current = [];
      
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
      
      setState({
        isRecording: false,
        duration: 0,
        audioBlob: null,
        audioUrl: null,
        error: null,
        audioLevel: 0,
        hasPermission: streamRef.current?.active || false
      });
    }
  }, [state.isRecording]);

  const reset = useCallback(() => {
    if (state.audioUrl) {
      URL.revokeObjectURL(state.audioUrl);
    }
    
    setState({
      isRecording: false,
      duration: 0,
      audioBlob: null,
      audioUrl: null,
      error: null,
      audioLevel: 0,
      hasPermission: streamRef.current?.active || false
    });
  }, [state.audioUrl]);

  // æ¸…ç†å‡½æ•° - é‡Šæ”¾MediaStream
  const cleanup = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    if (state.audioUrl) {
      URL.revokeObjectURL(state.audioUrl);
    }
    setState({
      isRecording: false,
      duration: 0,
      audioBlob: null,
      audioUrl: null,
      error: null,
      audioLevel: 0,
      hasPermission: false
    });
  }, [state.audioUrl]);

  return {
    ...state,
    ensurePermission,
    startRecording,
    stopRecording,
    cancelRecording,
    reset,
    cleanup
  };
}
