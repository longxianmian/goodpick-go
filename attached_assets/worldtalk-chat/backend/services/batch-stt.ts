/**
 * ========================================================================
 * éæµå¼è¯­éŸ³è¯†åˆ«æœåŠ¡ (Batch STT)
 * ========================================================================
 * 
 * ç”¨é€”ï¼šçŸ­è¯­éŸ³ä¸€æ¬¡æ€§è¯†åˆ«ï¼ˆå½•å®Œ â†’ ä¸Šä¼  â†’ è¿”å›ç»“æœï¼‰
 * 
 * æŠ€æœ¯æ¶æ„ï¼š
 *   å‰ç«¯å½•éŸ³å®Œæˆ â†’ æ•´æ®µéŸ³é¢‘ä¸Šä¼  â†’ ffmpeg è½¬ç ä¸º 16kHz mono WAV â†’ DashScope HTTP API
 * 
 * DashScope å‚æ•°ï¼š
 *   - model: paraformer-v2ï¼ˆéå®æ—¶ç‰ˆæœ¬ï¼‰
 *   - format: "wav"
 *   - sample_rate: 16000
 * 
 * API ç«¯ç‚¹ï¼šPOST /api/stt/recognize
 * 
 * ========================================================================
 */

import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs';
import path from 'path';
import os from 'os';

const execAsync = promisify(exec);

import { getDashScopeApiKey } from '../config/dashscope';

export async function recognizeAudioNonStreaming(audioBuffer: Buffer, audioFormat?: string): Promise<string> {
  const apiKey = getDashScopeApiKey();
  console.log('[dashscope] batch-stt DASHSCOPE_API_KEY prefix:', apiKey.slice(0, 8));

  const tempDir = os.tmpdir();
  const timestamp = Date.now();
  const inputFile = path.join(tempDir, `input_${timestamp}.${audioFormat || 'webm'}`);
  const outputFile = path.join(tempDir, `output_${timestamp}.wav`);

  try {
    fs.writeFileSync(inputFile, audioBuffer);
    console.log(`ğŸµ [Batch STT] ä¿å­˜è¾“å…¥æ–‡ä»¶: ${inputFile} (${audioBuffer.length} bytes)`);

    const ffmpegCmd = `ffmpeg -y -i "${inputFile}" -ac 1 -ar 16000 -acodec pcm_s16le "${outputFile}" 2>&1`;
    console.log(`ğŸ”„ [Batch STT] æ‰§è¡Œè½¬ç ...`);
    
    try {
      await execAsync(ffmpegCmd, { timeout: 30000 });
    } catch (ffmpegError: any) {
      console.error(`âŒ [Batch STT] ffmpegè½¬ç å¤±è´¥:`, ffmpegError.stderr || ffmpegError.message);
      throw new Error(`éŸ³é¢‘è½¬ç å¤±è´¥: ${ffmpegError.message}`);
    }

    if (!fs.existsSync(outputFile)) {
      throw new Error('ffmpegè½¬ç è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨');
    }

    const wavBuffer = fs.readFileSync(outputFile);
    console.log(`âœ… [Batch STT] è½¬ç å®Œæˆ: ${wavBuffer.length} bytes`);

    const recognitionResult = await callDashScopeParaformerHTTP(wavBuffer);
    console.log(`ğŸ¯ [Batch STT] è¯†åˆ«ç»“æœ: "${recognitionResult.substring(0, 50)}..."`);

    return recognitionResult;
  } finally {
    try {
      if (fs.existsSync(inputFile)) fs.unlinkSync(inputFile);
      if (fs.existsSync(outputFile)) fs.unlinkSync(outputFile);
    } catch (e) {
      console.warn('[Batch STT] Cleanup warning:', e);
    }
  }
}

/**
 * è°ƒç”¨DashScope Paraformeréå®æ—¶APIï¼ˆä½¿ç”¨file-urlsæ–¹å¼ï¼‰
 * ç”±äºmultipartå¤æ‚ï¼Œæ”¹ç”¨base64 + JSONæ–¹å¼
 */
async function callDashScopeParaformerHTTP(wavBuffer: Buffer): Promise<string> {
  const apiKey = getDashScopeApiKey();
  const apiUrl = 'https://dashscope.aliyuncs.com/api/v1/services/audio/asr/transcription';

  const audioBase64 = wavBuffer.toString('base64');
  
  const requestBody = {
    model: 'paraformer-v2',
    input: {
      audio: `data:audio/wav;base64,${audioBase64}`
    },
    parameters: {
      sample_rate: 16000,
      format: 'wav',
      language_hints: ['zh', 'en']
    }
  };

  console.log(`ğŸ“¡ [DashScope] å‘é€è¯†åˆ«è¯·æ±‚...`);

  const response = await fetch(apiUrl, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json',
      'X-DashScope-Async': 'enable'
    },
    body: JSON.stringify(requestBody)
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error(`âŒ [DashScope] APIé”™è¯¯: ${response.status}`, errorText);
    throw new Error(`DashScope API error: ${response.status} - ${errorText}`);
  }

  const result = await response.json() as any;
  console.log(`ğŸ“ [DashScope] å“åº”:`, JSON.stringify(result, null, 2));

  if (result.output?.task_status === 'PENDING') {
    return await pollTranscriptionTask(result.output.task_id);
  }

  return extractTranscription(result);
}

async function pollTranscriptionTask(taskId: string, maxAttempts = 30): Promise<string> {
  const apiKey = getDashScopeApiKey();
  const statusUrl = `https://dashscope.aliyuncs.com/api/v1/tasks/${taskId}`;
  
  for (let attempt = 0; attempt < maxAttempts; attempt++) {
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    const response = await fetch(statusUrl, {
      headers: {
        'Authorization': `Bearer ${apiKey}`
      }
    });

    if (!response.ok) {
      throw new Error(`Task status check failed: ${response.status}`);
    }

    const result = await response.json() as any;
    const status = result.output?.task_status;

    if (status === 'SUCCEEDED') {
      return extractTranscription(result);
    } else if (status === 'FAILED') {
      throw new Error(`Transcription failed: ${result.output?.message || 'Unknown error'}`);
    }

    console.log(`â³ [DashScope] ä»»åŠ¡çŠ¶æ€: ${status} (${attempt + 1}/${maxAttempts})`);
  }

  throw new Error('Transcription timeout');
}

function extractTranscription(result: any): string {
  if (result.output?.results?.[0]?.transcription_url) {
    return result.output.results[0].transcription_url;
  }
  
  if (result.output?.sentence?.text) {
    return result.output.sentence.text;
  }
  
  if (result.output?.text) {
    return result.output.text;
  }

  const sentences = result.output?.results?.[0]?.sentences || [];
  if (sentences.length > 0) {
    return sentences.map((s: any) => s.text).join('');
  }

  return '';
}
