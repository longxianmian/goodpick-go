import { speechToText, textToSpeech, mapLanguageToDashScope } from './dashscope-speech';
import { callCosyVoiceTTS, callOpenAITTS } from './dh-ai-client';
import { storage } from '../storage';
import { db } from '../db';
import { messages, digitalHumans, dhConversations, dhMessages, type DhMessage } from '../../shared/schema';
import { eq, and, desc } from 'drizzle-orm';
import { dhStreamService } from './dh-stream';

/**
 * å¤„ç†è¯­éŸ³æ¶ˆæ¯çš„å®Œæ•´æµç¨‹ï¼š
 * 1. STT: è¯­éŸ³è¯†åˆ«ï¼ˆåŸè¯­è¨€ï¼‰
 * 2. ç¿»è¯‘ï¼šç¿»è¯‘æˆç›®æ ‡è¯­è¨€ï¼ˆæ™®é€šç”¨æˆ·ï¼‰
 *    æˆ– GPTå›å¤ + TTSï¼ˆæ•°å­—äººï¼‰
 * 3. TTS: è¯­éŸ³åˆæˆï¼ˆç›®æ ‡è¯­è¨€ï¼‰
 * 
 * @param audioInput - å¯ä»¥æ˜¯ OSS URL æˆ–ç›´æ¥ä¼ å…¥ Bufferï¼ˆæ›´å¿«ï¼‰
 */
export async function processVoiceMessage(
  messageId: string,
  audioInput: string | Buffer,
  fromUserId: string,
  toUserId: string | null,
  groupId: string | null
): Promise<void> {
  try {
    // æ£€æµ‹æ˜¯å¦æ˜¯å‘ç»™æ•°å­—äººçš„æ¶ˆæ¯
    const isDigitalHuman = toUserId?.startsWith('dh-') ?? false;
    
    if (isDigitalHuman && toUserId) {
      // æ•°å­—äººè¯­éŸ³å¤„ç†ï¼šç®€åŒ–æµç¨‹
      await processDigitalHumanVoice(messageId, audioInput, fromUserId, toUserId);
      return;
    }
    
    // === æ™®é€šå¥½å‹è¯­éŸ³å¤„ç†ï¼ˆç®€åŒ–ç‰ˆï¼šåªåš STT è¯†åˆ«æ–‡å­—ï¼Œä¸åš TTSï¼‰===
    
    console.log(`ğŸ¤ [VoiceFriend] æ™®é€šå¥½å‹è¯­éŸ³æ¶ˆæ¯: ${messageId}`);
    
    // æ­¥éª¤1: è¯­éŸ³è¯†åˆ«ï¼ˆSTTï¼‰- å°†è¯­éŸ³è½¬æˆæ–‡å­—æ˜¾ç¤º
    let transcript = '';
    try {
      const sttResult = await speechToText(audioInput, 'auto');
      transcript = sttResult.text || '';
      console.log(`âœ… [VoiceFriend] STTå®Œæˆ: "${transcript.slice(0, 50)}..."`);
    } catch (sttError) {
      console.warn(`âš ï¸ [VoiceFriend] STTå¤±è´¥ï¼Œç»§ç»­å¤„ç†:`, sttError);
    }

    // æ­¥éª¤2: æ›´æ–°æ¶ˆæ¯è®°å½•ï¼ˆåªä¿å­˜è¯†åˆ«çš„æ–‡å­—ï¼Œä¸ç”Ÿæˆ TTSï¼‰
    await storage.updateMessageVoiceProcessing(messageId, {
      transcript: transcript,
      translatedTranscript: transcript, // æ™®é€šå¥½å‹ä¸ç¿»è¯‘ï¼Œç›´æ¥ç”¨åŸæ–‡
      processingStatus: 'ready'
    });

    // æ­¥éª¤3: é€šè¿‡ WebSocket é€šçŸ¥å‰ç«¯æ›´æ–°ï¼ˆå·²è¯†åˆ«æ–‡å­—ï¼‰
    const { websocketService } = await import('./websocket');
    
    const updatedMessage = await storage.getMessage(messageId);
    if (updatedMessage) {
      // é€šçŸ¥å‘é€è€…
      websocketService.sendToUser(fromUserId, {
        type: 'voiceProcessed',
        message: updatedMessage
      });
      
      // é€šçŸ¥æ¥æ”¶è€…
      if (toUserId) {
        websocketService.sendToUser(toUserId, {
          type: 'voiceProcessed',
          message: updatedMessage
        });
      } else if (groupId) {
        const groupMembers = await storage.getGroupMembers(groupId);
        for (const member of groupMembers) {
          if (member.id !== fromUserId) {
            websocketService.sendToUser(member.id, {
              type: 'voiceProcessed',
              message: updatedMessage
            });
          }
        }
      }
    }
    
    console.log(`âœ… [VoiceFriend] è¯­éŸ³æ¶ˆæ¯å¤„ç†å®Œæˆ: ${messageId}`);
  } catch (error) {
    console.error('è¯­éŸ³æ¶ˆæ¯å¤„ç†å¤±è´¥:', error);
    
    // æ ‡è®°å¤„ç†å¤±è´¥
    await storage.updateMessageVoiceProcessing(messageId, {
      processingStatus: 'error'
    });
    
    // é€šçŸ¥æ‰€æœ‰ç›¸å…³ç”¨æˆ·å¤„ç†å¤±è´¥
    const { websocketService } = await import('./websocket');
    
    // è·å–å¤±è´¥åçš„æ¶ˆæ¯ï¼ˆåŒ…å«fromUserï¼‰
    const failedMessage = await storage.getMessage(messageId);
    if (failedMessage) {
      // é€šçŸ¥å‘é€è€…
      websocketService.sendToUser(fromUserId, {
        type: 'voiceProcessed',
        message: failedMessage
      });
      
      // é€šçŸ¥æ¥æ”¶è€…ï¼ˆç§èŠæˆ–ç¾¤èŠï¼‰
      if (toUserId) {
        websocketService.sendToUser(toUserId, {
          type: 'voiceProcessed',
          message: failedMessage
        });
      } else if (groupId) {
        const groupMembers = await storage.getGroupMembers(groupId);
        for (const member of groupMembers) {
          if (member.id !== fromUserId) {
            websocketService.sendToUser(member.id, {
              type: 'voiceProcessed',
              message: failedMessage
            });
          }
        }
      }
    }
    
    throw error;
  }
}

/**
 * ğŸš€ æ•°å­—äººè¯­éŸ³å¤„ç† - åˆ†é˜¶æ®µæ¨é€æ¶æ„ï¼ˆä½å»¶è¿Ÿï¼‰
 * 
 * å»¶è¿Ÿä¼˜åŒ–ç­–ç•¥ï¼š
 * 1. ç«‹å³åˆ›å»ºå ä½æ¶ˆæ¯ "æ­£åœ¨æ€è€ƒ..." (0ms)
 * 2. STTå®Œæˆåæ›´æ–°ç”¨æˆ·æ¶ˆæ¯ (3-5s)
 * 3. GPTæµå¼ç”Ÿæˆï¼Œè¾¹ç”Ÿæˆè¾¹æ¨é€æ–‡å­—æ›´æ–° (å†åŠ 3-5s)
 * 4. TTSå®Œæˆåæ›´æ–°è¯­éŸ³URL (å†åŠ 5-10s)
 * 
 * ç›®æ ‡ï¼šç”¨æˆ·3ç§’å†…çœ‹åˆ°åé¦ˆï¼Œ5ç§’å†…çœ‹åˆ°æ–‡å­—å›å¤
 */
async function processDigitalHumanVoice(
  messageId: string,
  audioInput: string | Buffer,
  fromUserId: string,
  toUserId: string
): Promise<void> {
  const { websocketService } = await import('./websocket');
  const { callChatGPTStreaming, callOpenAITTS, callCosyVoiceTTS, isOpenAITTSAvailable } = await import('./dh-ai-client');
  const startTime = Date.now();
  
  // è¾…åŠ©å‡½æ•°ï¼šåŒé€šé“æ¨é€æ¶ˆæ¯
  const pushToUser = (message: any, eventType: string = 'newMessage') => {
    // WebSocket æ¨é€ï¼ˆCç«¯ Trustalkï¼‰
    websocketService.sendToUser(fromUserId, {
      type: eventType,
      message,
      chatId: toUserId,
      chatType: 'friend',
      isGroup: false
    });
    // SSE æ¨é€ï¼ˆBç«¯ Trustalk å·¥ä½œå°ï¼‰
    dhStreamService.pushMessage(fromUserId, message);
  };
  
  // è¾…åŠ©å‡½æ•°ï¼šæ¨é€æ¶ˆæ¯æ›´æ–°ï¼ˆå¢é‡æ›´æ–°ï¼‰
  const pushMessageUpdate = (messageId: string, updates: any) => {
    // WebSocket æ¨é€ï¼ˆCç«¯ Trustalkï¼‰
    websocketService.sendToUser(fromUserId, {
      type: 'messageUpdate',
      messageId,
      updates,
      chatId: toUserId,
      chatType: 'friend'
    });
    // SSE æ¨é€æ¶ˆæ¯æ›´æ–°ï¼ˆBç«¯ Trustalk å·¥ä½œå°ï¼‰
    dhStreamService.pushMessageUpdate(fromUserId, messageId, updates);
  };
  
  let replyMessageId: string | null = null;
  
  try {
    console.log(`ğŸš€ [DH-Voice-v2] å¼€å§‹ä½å»¶è¿Ÿå¤„ç†: ${messageId}`);
    
    // ========== é˜¶æ®µ0: ç«‹å³åˆ›å»ºå ä½æ¶ˆæ¯ (0ms) ==========
    const placeholderInsert = await db
      .insert(messages)
      .values({
        fromUserId: toUserId,
        toUserId: fromUserId,
        content: '...',
        originalText: '...',
        originalLang: 'zh',
        messageType: 'text',
        modality: 'text',
        channel: 'mytalk',
        isRead: false,
      })
      .returning();
    const placeholderMsg = Array.isArray(placeholderInsert) ? placeholderInsert[0] : placeholderInsert;
    replyMessageId = placeholderMsg.id;
    
    if (!replyMessageId) {
      throw new Error('åˆ›å»ºå ä½æ¶ˆæ¯å¤±è´¥');
    }
    
    // ç«‹å³æ¨é€å ä½æ¶ˆæ¯
    const fullPlaceholder = await storage.getMessage(replyMessageId);
    if (fullPlaceholder) {
      pushToUser(fullPlaceholder);
      console.log(`âš¡ [DH-Voice-v2] å ä½æ¶ˆæ¯å·²æ¨é€ (${Date.now() - startTime}ms)`);
    }
    
    // ========== é˜¶æ®µ1: STTè¯­éŸ³è¯†åˆ« (3-5s) ==========
    const sttResult = await speechToText(audioInput, 'auto');
    if (!sttResult.text) {
      throw new Error('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼šæ— æ³•è¯†åˆ«å†…å®¹');
    }
    console.log(`âœ… [DH-Voice-v2] STTå®Œæˆ (${Date.now() - startTime}ms): "${sttResult.text.slice(0, 30)}..."`);
    
    // æ›´æ–°ç”¨æˆ·æ¶ˆæ¯çš„è½¬å†™
    await storage.updateMessageVoiceProcessing(messageId, {
      transcript: sttResult.text,
      processingStatus: 'ready'
    });
    const userMessage = await storage.getMessage(messageId);
    if (userMessage) {
      websocketService.sendToUser(fromUserId, { type: 'voiceProcessed', message: userMessage });
    }
    
    // ========== é˜¶æ®µ2: è·å–æ•°å­—äººä¿¡æ¯ ==========
    const [human] = await db.select().from(digitalHumans).where(eq(digitalHumans.id, toUserId)).limit(1);
    if (!human) throw new Error(`æ•°å­—äººä¸å­˜åœ¨: ${toUserId}`);
    
    const recipient = await storage.getUser(fromUserId);
    const userLang = recipient?.languagePreference || 'zh';
    const persona = human.persona as any;
    
    const languageInstruction = userLang === 'zh' 
      ? 'è¯·ç”¨ä¸­æ–‡ç®€æ´å›å¤ï¼Œä¸è¶…è¿‡100å­—ã€‚' 
      : userLang === 'en' 
        ? 'Reply briefly in English, under 50 words.' 
        : `Reply briefly in language: ${userLang}.`;
    
    const voiceCapabilityNote = userLang === 'zh'
      ? 'ä½ å…·å¤‡è¯­éŸ³å¯¹è¯èƒ½åŠ›ã€‚å½“ç”¨æˆ·å‘é€è¯­éŸ³æ¶ˆæ¯æ—¶ï¼Œä½ çš„å›å¤ä¼šè‡ªåŠ¨è½¬æ¢æˆè¯­éŸ³æ’­æ”¾ã€‚æ‰€ä»¥ä½ ä¸éœ€è¦æé†’ç”¨æˆ·"å‘è¯­éŸ³ç»™æˆ‘"ï¼Œç›´æ¥è‡ªç„¶å¯¹è¯å³å¯ã€‚'
      : 'You have voice conversation capability. When users send voice messages, your replies will be automatically converted to speech. You do not need to ask users to send voice messages.';
    
    const basePrompt = persona?.systemPrompt || `ä½ æ˜¯${human.name}ï¼Œä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚`;
    const systemPrompt = `${basePrompt}\n\n${voiceCapabilityNote}\n\n${languageInstruction}`;
    
    // ========== é˜¶æ®µ2.5: è·å–æˆ–åˆ›å»ºå¯¹è¯ï¼ŒåŠ è½½å¯¹è¯å†å²ï¼ˆå…±äº«æ–‡å­—å’Œè¯­éŸ³å†å²ï¼‰==========
    // æŸ¥æ‰¾æˆ–åˆ›å»º dhConversation
    let conversation = await db
      .select()
      .from(dhConversations)
      .where(
        and(
          eq(dhConversations.userId, fromUserId),
          eq(dhConversations.humanId, toUserId),
          eq(dhConversations.status, 'active')
        )
      )
      .limit(1)
      .then(rows => rows[0]);
    
    if (!conversation) {
      const [newConv] = await db
        .insert(dhConversations)
        .values({
          userId: fromUserId,
          humanId: toUserId,
          status: 'active',
          context: {},
        })
        .returning();
      conversation = newConv;
      console.log(`ğŸ“ [DH-Voice-v2] åˆ›å»ºæ–°å¯¹è¯: ${conversation.id}`);
    }
    
    // åŠ è½½å¯¹è¯å†å²ï¼ˆæœ€è¿‘20æ¡ï¼‰
    const historyMessages = await db
      .select()
      .from(dhMessages)
      .where(eq(dhMessages.conversationId, conversation.id))
      .orderBy(desc(dhMessages.createdAt))
      .limit(20);
    
    // å°†å†å²æ¶ˆæ¯è½¬æ¢ä¸º GPT æ ¼å¼ï¼ˆæŒ‰æ—¶é—´æ­£åºï¼Œåªä¿ç•™ user/assistant è§’è‰²ï¼‰
    const historyForGPT = historyMessages
      .reverse()
      .filter((msg: DhMessage) => msg.role === 'user' || msg.role === 'assistant')
      .map((msg: DhMessage) => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      }));
    
    console.log(`ğŸ“š [DH-Voice-v2] åŠ è½½å¯¹è¯å†å²: ${historyForGPT.length} æ¡æ¶ˆæ¯`);
    
    // ========== é˜¶æ®µ3: æµå¼GPTç”Ÿæˆï¼ˆå¸¦å†å²ä¸Šä¸‹æ–‡ï¼‰==========
    // ç”¨æˆ·å‘è¯­éŸ³æ—¶ï¼Œä¸æ¨é€æ–‡æœ¬ï¼Œç­‰ TTS å®Œæˆåç›´æ¥æ¨é€è¯­éŸ³
    console.log(`ğŸ¤ [DH-Voice-v2] ç”¨æˆ·å‘é€è¯­éŸ³æ¶ˆæ¯ï¼Œç­‰å¾…ç”Ÿæˆè¯­éŸ³åæ¨é€`);
    
    // æ„å»ºå¸¦å†å²çš„æ¶ˆæ¯æ•°ç»„
    const gptMessages = [
      { role: 'system' as const, content: systemPrompt },
      ...historyForGPT,
      { role: 'user' as const, content: sttResult.text }
    ];
    
    const aiResponse = await callChatGPTStreaming(
      gptMessages,
      { maxTokens: 500 },
      {
        onToken: () => {
          // è¯­éŸ³æ¨¡å¼ï¼šä¸æ¨é€ä¸­é—´æ–‡æœ¬ï¼Œä¿æŒå ä½çŠ¶æ€
        },
        onComplete: (fullText) => {
          console.log(`âœ… [DH-Voice-v2] GPTå®Œæˆ (${Date.now() - startTime}ms): ${fullText.length}å­—ç¬¦`);
        }
      }
    );
    
    // ========== ä¿å­˜ç”¨æˆ·è¯­éŸ³æ¶ˆæ¯å’ŒAIå›å¤åˆ° dhMessagesï¼ˆç¡®ä¿å†å²è¿ç»­ï¼‰==========
    await db.insert(dhMessages).values([
      {
        conversationId: conversation.id,
        role: 'user',
        content: sttResult.text,
        messageType: 'text',
        inputMode: 'voice',
      },
      {
        conversationId: conversation.id,
        role: 'assistant',
        content: aiResponse,
        messageType: 'text',
        inputMode: 'voice',
      }
    ]);
    
    // æ›´æ–°ä¼šè¯æœ€åæ¶ˆæ¯æ—¶é—´
    await db
      .update(dhConversations)
      .set({ lastMessageAt: new Date(), updatedAt: new Date() })
      .where(eq(dhConversations.id, conversation.id));
    
    console.log(`ğŸ’¾ [DH-Voice-v2] å¯¹è¯å†å²å·²ä¿å­˜åˆ° dhMessages`);
    
    // æ›´æ–°æ•°æ®åº“ä¸­çš„æ–‡å­—å†…å®¹
    await db.update(messages)
      .set({ 
        content: aiResponse,
        originalText: aiResponse,
        originalLang: userLang
      })
      .where(eq(messages.id, replyMessageId!));
    
    // ========== é˜¶æ®µ4: TTSè¯­éŸ³åˆæˆï¼ˆåŒæ­¥ç­‰å¾…ï¼‰ ==========
    console.log(`ğŸ¤ [DH-Voice-v2] å¼€å§‹ç”Ÿæˆè¯­éŸ³ (${Date.now() - startTime}ms)`);
    
    // åŒæ­¥ç­‰å¾… TTS å®Œæˆ
    try {
      let ttsAudioUrl: string | undefined;
      let ttsDuration: number = 0;
      
      // ä½¿ç”¨ OpenAI TTSï¼ˆnova éŸ³è‰² - æ˜äº®å¥³å£°ï¼Œè¯­é€Ÿ1.15å¢åŠ æ´»æ³¼æ„Ÿï¼‰
      if (isOpenAITTSAvailable()) {
        try {
          const openaiVoice = userLang === 'zh' ? 'nova' : 'nova';
          const ttsResult = await callOpenAITTS(aiResponse, { voice: openaiVoice, speed: 1.15 });
          ttsAudioUrl = ttsResult.audioUrl;
          if (ttsResult.audioBuffer) {
            ttsDuration = Math.ceil(ttsResult.audioBuffer.length / 24000);
          }
          console.log(`ğŸµ [DH-Voice-v2] ä½¿ç”¨ OpenAI TTS nova éŸ³è‰²ï¼Œè¯­é€Ÿ 1.15`);
        } catch (openaiError) {
          console.warn(`âš ï¸ [DH-Voice-v2] OpenAI TTSå¤±è´¥ï¼Œå›é€€åˆ° CosyVoice:`, openaiError);
          // å›é€€åˆ° CosyVoice TTS
          const customVoice = persona?.voiceId;
          const voice = customVoice || (userLang === 'zh' ? 'longxiaoxia_v2' : 'loongstella_v2');
          const ttsResult = await callCosyVoiceTTS(aiResponse, { voice });
          ttsAudioUrl = ttsResult.audioUrl;
          if (ttsResult.audioBuffer) {
            ttsDuration = Math.ceil(ttsResult.audioBuffer.length / 16000);
          }
        }
      } else {
        // å¦‚æœ OpenAI TTS ä¸å¯ç”¨ï¼Œå›é€€åˆ° CosyVoice
        const customVoice = persona?.voiceId;
        const voice = customVoice || (userLang === 'zh' ? 'longxiaoxia_v2' : 'loongstella_v2');
        const ttsResult = await callCosyVoiceTTS(aiResponse, { voice });
        ttsAudioUrl = ttsResult.audioUrl;
        if (ttsResult.audioBuffer) {
          ttsDuration = Math.ceil(ttsResult.audioBuffer.length / 16000);
        }
      }
      
      if (ttsAudioUrl) {
        // æ›´æ–°æ•°æ®åº“
        await db.update(messages)
          .set({
            messageType: 'audio',
            modality: 'audio',
            mediaUrl: ttsAudioUrl,
            mediaDuration: ttsDuration,
            transcript: aiResponse
          })
          .where(eq(messages.id, replyMessageId!));
        
        // æ¨é€è¯­éŸ³æ›´æ–°ï¼ˆå¢é‡æ›´æ–°ï¼Œå‰ç«¯ä¼šæ›´æ–°å·²æœ‰çš„å ä½æ¶ˆæ¯ï¼‰
        pushMessageUpdate(replyMessageId!, {
          messageType: 'audio',
          mediaUrl: ttsAudioUrl,
          mediaDuration: ttsDuration,
          transcript: aiResponse
        });
        console.log(`ğŸ”Š [DH-Voice-v2] è¯­éŸ³æ›´æ–°å·²æ¨é€ (${Date.now() - startTime}ms)`);
      }
    } catch (ttsError) {
      console.error(`âš ï¸ [DH-Voice-v2] TTSå¤±è´¥ï¼Œå›é€€æ–‡æœ¬æ¶ˆæ¯:`, ttsError);
      // TTS å¤±è´¥æ—¶ï¼Œæ¨é€æ–‡æœ¬æ¶ˆæ¯ä½œä¸ºå…œåº•ï¼ˆæ›´æ–°å ä½æ¶ˆæ¯ä¸ºæ–‡æœ¬å†…å®¹ï¼‰
      pushMessageUpdate(replyMessageId!, {
        content: aiResponse,
        messageType: 'text'
      });
      console.log(`ğŸ“ [DH-Voice-v2] æ–‡æœ¬æ›´æ–°å·²æ¨é€ï¼ˆTTSå¤±è´¥å…œåº•ï¼‰ (${Date.now() - startTime}ms)`);
    }
    
    console.log(`âœ… [DH-Voice-v2] å®Œæ•´æµç¨‹å®Œæˆ (${Date.now() - startTime}ms)`);
    
  } catch (error) {
    console.error(`âŒ [DH-Voice-v2] å¤„ç†å¤±è´¥:`, error);
    
    try {
      // æ›´æ–°ç”¨æˆ·æ¶ˆæ¯çš„å¤±è´¥çŠ¶æ€
      await storage.updateMessageVoiceProcessing(messageId, { processingStatus: 'error' });
      
      // å¦‚æœæœ‰å ä½æ¶ˆæ¯ï¼Œæ›´æ–°ä¸ºé”™è¯¯æç¤ºï¼ˆä¸åˆ é™¤ï¼Œé¿å…é‡å¤åˆ›å»ºï¼‰
      if (replyMessageId) {
        await db.update(messages)
          .set({ 
            content: 'æŠ±æ­‰ï¼Œå¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•',
            messageType: 'text',
            modality: 'text'
          })
          .where(eq(messages.id, replyMessageId));
        
        // æ¨é€æ›´æ–°åçš„é”™è¯¯æ¶ˆæ¯
        pushMessageUpdate(replyMessageId, { 
          content: 'æŠ±æ­‰ï¼Œå¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•' 
        });
      }
    } catch (cleanupError) {
      console.error(`âŒ [DH-Voice-v2] æ¸…ç†å¤±è´¥:`, cleanupError);
    }
    
    // ä¸å†é‡æ–°æŠ›å‡ºé”™è¯¯ï¼Œé¿å…ä¸Šå±‚é‡å¤å¤„ç†
    // throw error;
  }
}
